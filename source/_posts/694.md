---
title: 腾讯研究：大模型“上下文学习”比想象中更难，存在长尾效应
date: 2026-02-07 17:25:00
categories:
  - AI
tags:
  - 腾讯 AI Lab
  - ICL
  - 机器学习
  - 论文研读
---

腾讯 AI Lab 近日发布的一项研究指出，大语言模型的上下文学习（In-Context Learning, ICL）能力并非如外界想象般完美，在处理复杂任务时表现出显著的脆弱性。

### 📉 精度随复杂度骤降

研究团队发现：
*   **样本敏感度**：提示词中示例的顺序和分布会极大影响最终结果。
*   **泛化难题**：当任务逻辑超出预训练数据的常见范围时，ICL 的成功率会呈现断崖式下跌。

这一发现提醒开发者，在构建基于 ICL 的应用时，需要更加严谨的工程化手段来弥补模型天然的推理缺陷。
